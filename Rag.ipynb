{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72895ba4-5fac-4eec-a984-cc796290908c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  DEPRECATION: Building 'annoy' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'annoy'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  DEPRECATION: Building 'docopt' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'docopt'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "axolotl 0.13.0.dev0 requires pydantic==2.10.6, but you have pydantic 2.11.7 which is incompatible.\n",
      "axolotl 0.13.0.dev0 requires zstandard==0.22.0, but you have zstandard 0.23.0 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q torch transformers transformers accelerate datasets bitsandbytes attacut langchain sentence-transformers openpyxl pacmap ragatouille matplotlib \n",
    "!pip install -q -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2449d753-3b2e-41fb-aa57-5854251bd271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Tuple\n",
    "from datasets import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\n",
    "    \"display.max_colwidth\", None\n",
    ")  # this will be helpful when visualizing retriever outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e895dffe-2f2a-4319-89c6-01291fcc5984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌟 THAISUM - FIRST 500 ROWS LOADER\n",
      "==================================================\n",
      "🚀 Attempting simple pandas approach...\n",
      "📥 Loading first 500 rows using pandas...\n",
      "✅ Loaded 500 rows with 6 columns\n",
      "📋 Columns: ['title', 'body', 'summary', 'type', 'tags', 'url']\n",
      "🎉 Success!\n",
      "\n",
      "🎉 SUCCESS!\n",
      "📊 Dataset loaded: 500 samples\n",
      "🔑 Available fields: ['title', 'body', 'summary', 'type', 'tags', 'url']\n",
      "💡 Ready to use!\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "import requests\n",
    "from datasets import Dataset\n",
    "from io import StringIO\n",
    "\n",
    "def load_first_500_samples(url):\n",
    "    \"\"\"\n",
    "    Load only the first 500 rows from ThaiSum dataset efficiently\n",
    "    \"\"\"\n",
    "    print(\"📥 Loading first 500 samples from ThaiSum dataset...\")\n",
    "    print(f\"🌐 URL: {url}\")\n",
    "    \n",
    "    try:\n",
    "        # Use streaming to read only what we need\n",
    "        print(\"🔄 Starting streaming download...\")\n",
    "        \n",
    "        response = requests.get(url, stream=True, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        print(f\"✅ Connection successful! Status: {response.status_code}\")\n",
    "        \n",
    "        # Read line by line until we get 501 lines (header + 500 rows)\n",
    "        lines = []\n",
    "        line_count = 0\n",
    "        \n",
    "        print(\"📖 Reading first 500 rows...\")\n",
    "        \n",
    "        # Decode content and split into lines\n",
    "        content = \"\"\n",
    "        for chunk in response.iter_content(chunk_size=8192, decode_unicode=True):\n",
    "            if chunk:\n",
    "                content += chunk\n",
    "                \n",
    "                # Process complete lines\n",
    "                while '\\n' in content:\n",
    "                    line, content = content.split('\\n', 1)\n",
    "                    lines.append(line + '\\n')\n",
    "                    line_count += 1\n",
    "                    \n",
    "                    # Stop when we have header + 500 data rows\n",
    "                    if line_count >= 501:\n",
    "                        break\n",
    "                \n",
    "                if line_count >= 501:\n",
    "                    break\n",
    "        \n",
    "        print(f\"📊 Read {line_count} lines (including header)\")\n",
    "        \n",
    "        # Join lines and create CSV content\n",
    "        csv_content = ''.join(lines)\n",
    "        \n",
    "        # Read with pandas\n",
    "        print(\"🔄 Converting to DataFrame...\")\n",
    "        df = pd.read_csv(StringIO(csv_content))\n",
    "        \n",
    "        print(f\"✅ Successfully loaded {len(df)} rows!\")\n",
    "        print(f\"📋 Columns: {list(df.columns)}\")\n",
    "        \n",
    "        # Convert to Hugging Face Dataset\n",
    "        print(\"🔄 Converting to Hugging Face Dataset...\")\n",
    "        dataset = Dataset.from_pandas(df)\n",
    "        \n",
    "        print(\"🎉 Dataset ready!\")\n",
    "        \n",
    "        # Show sample\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"📄 FIRST SAMPLE:\")\n",
    "        print(\"=\"*60)\n",
    "        sample = dataset[0]\n",
    "        \n",
    "        for key, value in sample.items():\n",
    "            print(f\"\\n{key.upper()}:\")\n",
    "            if isinstance(value, str):\n",
    "                if len(value) > 150:\n",
    "                    print(f\"  {value[:150]}...\")\n",
    "                    print(f\"  [Length: {len(value)} characters]\")\n",
    "                else:\n",
    "                    print(f\"  {value}\")\n",
    "            else:\n",
    "                print(f\"  {value}\")\n",
    "        \n",
    "        # Show basic stats\n",
    "        if 'body' in dataset.column_names and 'summary' in dataset.column_names:\n",
    "            print(f\"\\n📈 QUICK STATS:\")\n",
    "            bodies = [len(str(dataset[i]['body']).split()) for i in range(min(50, len(dataset)))]\n",
    "            summaries = [len(str(dataset[i]['summary']).split()) for i in range(min(50, len(dataset)))]\n",
    "            \n",
    "            print(f\"Average body length: {sum(bodies)/len(bodies):.1f} words\")\n",
    "            print(f\"Average summary length: {sum(summaries)/len(summaries):.1f} words\")\n",
    "        \n",
    "        return dataset\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Even simpler approach using pandas directly\n",
    "def load_simple_pandas(url, n_rows=500):\n",
    "    \"\"\"\n",
    "    Simplest approach - let pandas handle it\n",
    "    \"\"\"\n",
    "    print(f\"📥 Loading first {n_rows} rows using pandas...\")\n",
    "    \n",
    "    try:\n",
    "        # Pandas can read first N rows directly from URL\n",
    "        df = pd.read_csv(url, nrows=n_rows)\n",
    "        \n",
    "        print(f\"✅ Loaded {len(df)} rows with {len(df.columns)} columns\")\n",
    "        print(f\"📋 Columns: {list(df.columns)}\")\n",
    "        \n",
    "        # Convert to HuggingFace Dataset\n",
    "        dataset = Dataset.from_pandas(df)\n",
    "        \n",
    "        print(\"🎉 Success!\")\n",
    "        return dataset\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Pandas approach failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main execution\n",
    "url = \"https://nakhun-chumpolsathien.oss-us-west-1.aliyuncs.com/thaisum/thaisum.csv\"\n",
    "\n",
    "print(\"🌟 THAISUM - FIRST 500 ROWS LOADER\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Try the simplest approach first\n",
    "print(\"🚀 Attempting simple pandas approach...\")\n",
    "ds = load_simple_pandas(url, 500)\n",
    "\n",
    "if ds is None:\n",
    "    print(\"\\n🔄 Trying streaming approach...\")\n",
    "    ds = load_first_500_samples(url)\n",
    "\n",
    "# Result\n",
    "if ds is not None:\n",
    "    print(f\"\\n🎉 SUCCESS!\")\n",
    "    print(f\"📊 Dataset loaded: {len(ds)} samples\")\n",
    "    print(f\"🔑 Available fields: {list(ds.features.keys())}\")\n",
    "    print(f\"💡 Ready to use!\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n❌ Failed to load dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14afdb14-4550-4146-83bc-660a009d7ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': ' วิษณุ ยันโรดแม็ปเดิม ตอบไม่ถูกเวลาเลือกตั้ง ต้องรอ รธน.ประกาศใช้',\n",
       " 'body': 'เมื่อวันที่ 6 ม.ค.60 ที่ทำเนียบรัฐบาล นายวิษณุ เครืองาม รองนายกรัฐมนตรี กล่าวถึงกรณี ที่ นายสุรชัย เลี้ยงบุญเลิศชัย รองประธานสภานิติบัญญัติแห่งชาติ (สนช.) ออกมาระบุว่า การเลือกตั้งจะถูกเลื่อนออกไปถึงปี 2561 ว่า ขอให้ไปสอบถามกับ สนช. แต่เชื่อว่าคงไม่กล้าพูดอีก เพราะทำให้คนเข้าใจผิด ซึ่งที่ สนช.พูดเนื่องจากผูกกับกฎหมายของกรรมการร่างรัฐธรรมนูญ(กรธ.) ตนจึงไม่ขอวิพากษ์วิจารณ์ แต่รัฐบาลยืนยันว่ายังเดินตามโรดแม็ป ซึ่งโรดแม็ปมองได้สองแบบ คือ มีลำดับขั้นตอนและการกำหนดช่วงเวลา โดยเริ่มต้นจากการประกาศใช้รัฐธรรมนูญ แต่ขณะนี้รัฐธรรมนูญยังไม่ประกาศใช้ จึงยังเริ่มนับหนึ่งไม่ถูก จากนั้นเข้าสู่ขั้นตอนการร่างกฎหมายประกอบร่างรัฐธรรมนูญหรือกฎหมายลูก ภายใน 240 วัน ก่อนจะส่งกลับให้ สนช.พิจารณา ภายใน 2 เดือน\\xa0,นายวิษณุ กล่าวต่อว่า หากมีการแก้ไขก็จะมีการพิจารณาร่วมกับ กรธ.อีก 1 เดือน ก่อนนำขึ้นทูลเกล้าฯ ทรงลงพระปรมาภิไธย ภายใน 90 วัน และจะเข้าสู่การเลือกตั้งภายในระยะเวลา 5 เดือน ซึ่งทั้งหมดนี้คือโรดแม็ปที่ยังเป็นแบบเดิมอยู่ ส่วนเดิมที่กำหนดวันเลือกตั้งไว้ภายในปี 60 นั้น เพราะมาจากสมมติฐานของขั้นตอนเดิมทั้งหมด แต่เมื่อมีเหตุสวรรคตทุกอย่างจึงต้องเลื่อนออกไป ส่วนการพิจารณากฎหมายลูกทั้งหมด 4 ฉบับ ขณะนี้กรธ.พิจารณาแล้วเสร็จ 2 ฉบับ คือ พ.ร.ป.พรรคการเมือง และพ.ร.ป. คณะกรรมการการเลือกตั้ง แต่ พ.ร.ป.การเลือกตั้งควรจะพิจารณาได้เร็วกลับล่าช้า ดังนั้น กรธ.จะต้องออกชี้แจงถึงเหตุผลว่าทำไมพิจารณากฎหมายดังกล่าวล่าช้ากว่ากำหนด ส่งผลให้เกิดข้อสงสัยจนถึงทุกวันนี้ ส่วนกรณีที่ สนช. ระบุว่า มีกฎหมายเข้าสู่การพิจารณาของ สนช.เป็นจำนวนมาก ทำให้ส่งผลกระทบต่อโรดแม็ปนั้น รัฐบาลเคยบอกไว้แล้วว่าในช่วงนี้ของโรดแม็ปกฎหมายจะเยอะกว่าที่ผ่านมา ดังนั้น สนช.จะต้องบริหารจัดการกันเอง เพราะได้มีการเพิ่มสมาชิก สนช.ให้แล้ว.',\n",
       " 'summary': 'วิษณุ ยันโรดแม็ปตามขั้นตอนเดิม เชื่อ สนช.หยุดพูดขยับเลือกตั้ง ปัดวิจารณ์ ยึดตามกรอบเวลา ย้ำเริ่มนับโรดแม็ปเมื่อ รธน.ประกาศใช้',\n",
       " 'type': None,\n",
       " 'tags': 'เลือกตั้ง,โรดแม็ป,วิษณุ เครืองาม,ร่างรัฐธรรมนูญ,สนช.',\n",
       " 'url': 'https://www.thairath.co.th/content/829502'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42db00c6-078a-4c43-9370-5d50c0795b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbaf425e41ac4711a61497afb8fc1135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing Thai text:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize\n",
    "from attacut import Tokenizer\n",
    "\n",
    "atta = Tokenizer(model=\"attacut-sc\")\n",
    "\n",
    "def tokenize_batch(examples):\n",
    "    \"\"\"Process multiple texts at once\"\"\"\n",
    "    tokenized_bodies = []\n",
    "    for body in examples['body']:\n",
    "        if body:\n",
    "            tokens = atta.tokenize(body)\n",
    "            tokenized_bodies.append(\" \".join(tokens))\n",
    "        else:\n",
    "            tokenized_bodies.append(\"\")\n",
    "    return {'tokenized_body': tokenized_bodies}\n",
    "\n",
    "ds_tok = ds.map(\n",
    "    tokenize_batch,\n",
    "    batched=True,          \n",
    "    batch_size=20,  \n",
    "    remove_columns=['body'],\n",
    "    desc=\"Tokenizing Thai text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84a709fc-2fb5-43d5-b1ec-03d8c224835b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'เมื่อ วัน ที่   6   ม. ค. 60   ที่ ทำเนียบรัฐบาล   นายวิษณุ เครืองาม   รอง นายก รัฐมนตรี   กล่าว ถึง กรณี   ที่   นายสุรชัย เลี้ยงบุญเลิศชัย   รอง ประธาน สภานิติบัญญัติแห่งชาติ   ( สนช. )   ออก มา ระบุ ว่า   การ เลือกตั้ง จะ ถูก เลื่อน ออก ไป ถึง ปี   2561   ว่า   ขอ ให้ ไป สอบถาม กับ   สนช.   แต่ เชื่อ ว่า คง ไม่ กล้า พูด อีก   เพราะ ทำ ให้ คน เข้าใจ ผิด   ซึ่ง ที่   สนช. พูด เนื่อง จาก ผูก กับ กฎหมาย ของ กรรมการ ร่าง รัฐธรรมนูญ ( กร ธ. )   ตน จึง ไม่ ขอ วิพากษ์วิจารณ์   แต่ รัฐบาล ยืนยัน ว่า ยัง เดิน ตาม โรด แม็ป   ซึ่ง โรด แม็ป มอง ได้ สอง แบบ   คือ   มี ลำดับ ขั้นตอน และ การ กำหนด ช่วง เวลา   โดย เริ่มต้น จาก การ ประกาศ ใช้ รัฐธรรมนูญ   แต่ ขณะ นี้ รัฐธรรมนูญ ยัง ไม่ ประกาศ ใช้   จึง ยัง เริ่ม นับ หนึ่ง ไม่ ถูก   จาก นั้น เข้า สู่ ขั้นตอน การ ร่าง กฎหมาย ประกอบ ร่าง รัฐธรรมนูญ หรือ กฎหมาย ลูก   ภาย ใน   240   วัน   ก่อน จะ ส่ง กลับ ให้   สนช. พิจารณา   ภาย ใน   2   เดือน \\xa0 , นายวิษณุ   กล่าว ต่อ ว่า   หาก มี การ แก้ไข ก็ จะ มี การ พิจารณา ร่วม กับ   กร ธ. อีก   1   เดือน   ก่อน นำ ขึ้น ทูลเกล้า ฯ   ทรง ลง พระปรมาภิไธย   ภาย ใน   90   วัน   และ จะ เข้า สู่ การ เลือกตั้ง ภาย ใน ระยะ เวลา   5   เดือน   ซึ่ง ทั้งหมด นี้ คือ โรดแม็ป ที่ ยัง เป็น แบบ เดิม อยู่   ส่วน เดิม ที่ กำหนด วัน เลือกตั้ง ไว้ ภาย ใน ปี   60   นั้น   เพราะ มา จาก สมมติฐาน ของ ขั้นตอน เดิม ทั้งหมด   แต่ เมื่อ มี เหตุ สวรรคต ทุก อย่าง จึง ต้อง เลื่อน ออก ไป   ส่วน การ พิจารณา กฎหมาย ลูก ทั้งหมด   4   ฉบับ   ขณะ นี้ กรธ. พิจารณา แล้วเสร็จ   2   ฉบับ   คือ   พ.ร.ป. พรรค การ เมือง   และ พ.ร.ป.   คณะกรรมการการเลือกตั้ง   แต่   พ.ร.ป. การ เลือกตั้ง ควร จะ พิจารณา ได้ เร็ว กลับ ล่าช้า   ดัง นั้น   กร ธ. จะ ต้อง ออก ชี้แจง ถึง เหตุผล ว่า ทำไม พิจารณา กฎหมาย ดัง กล่าว ล่าช้า กว่า กำหนด   ส่ง ผล ให้ เกิด ข้อ สงสัย จนถึง ทุก วัน นี้   ส่วน กรณี ที่   สนช.   ระบุ ว่า   มี กฎหมาย เข้า สู่ การ พิจารณา ของ   สนช. เป็น จำนวน มาก   ทำ ให้ ส่ง ผล กระทบ ต่อ โรด แม็ป นั้น   รัฐบาล เคย บอก ไว้ แล้ว ว่า ใน ช่วง นี้ ของ โรดแม็ป กฎหมาย จะ เยอะกว่า ที่ ผ่าน มา   ดัง นั้น   สนช. จะ ต้อง บริหารจัดการ กัน เอง   เพราะ ได้ มี การ เพิ่ม สมาชิก   สนช. ให้ แล้ว .'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_tok[0]['tokenized_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e5f7e16-ebe4-4bd5-9198-8cab6b0d3147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 6589.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Import to Knowledge Base\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "\n",
    "RAW_KNOWLEDGE_BASE = [\n",
    "    LangchainDocument(page_content=doc[\"body\"], metadata={\"source\": doc[\"url\"]})\n",
    "    for doc in tqdm(ds)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4d88972-4db8-4158-b8a6-25295d6ccbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sentence\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "MARKDOWN_SEPARATORS = [\n",
    "    \"\\n#{1,6} \",\n",
    "    \"```\\n\",\n",
    "    \"\\n\\\\*\\\\*\\\\*+\\n\",\n",
    "    \"\\n---+\\n\",\n",
    "    \"\\n___+\\n\",\n",
    "    \"\\n\\n\",\n",
    "    \"\\n\",\n",
    "    \" \",\n",
    "    \"\",\n",
    "]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    add_start_index=True,\n",
    "    strip_whitespace=True,\n",
    "    separators=MARKDOWN_SEPARATORS,\n",
    ")\n",
    "\n",
    "docs_processed = []\n",
    "for doc in RAW_KNOWLEDGE_BASE:\n",
    "    docs_processed += text_splitter.split_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1494ae8e-be67-4b00-b315-0270be9b8316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's maximum sequence length: 128\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sentence_embedding_path = \"sentence-transformers/distiluse-base-multilingual-cased-v2\"\n",
    "\n",
    "print(\n",
    "    f\"Model's maximum sequence length: {SentenceTransformer(sentence_embedding_path).max_seq_length}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94151b9f-793c-4d34-ae76-413f2e35964b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 479/500 [00:18<00:00, 26.23it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 500/500 [00:19<00:00, 25.35it/s]\n",
      "100%|██████████| 2061/2061 [00:00<00:00, 710717.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Split document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "EMBEDDING_MODEL_NAME = sentence_embedding_path\n",
    "\n",
    "\n",
    "def split_documents(\n",
    "    chunk_size: int,\n",
    "    knowledge_base: List[LangchainDocument],\n",
    "    tokenizer_name: Optional[str] = EMBEDDING_MODEL_NAME,\n",
    ") -> List[LangchainDocument]:\n",
    "    \"\"\"\n",
    "    Split documents into chunks of maximum size `chunk_size` tokens and return a list of documents.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "        AutoTokenizer.from_pretrained(tokenizer_name),\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=int(chunk_size / 10),\n",
    "        add_start_index=True,\n",
    "        strip_whitespace=True,\n",
    "        separators=MARKDOWN_SEPARATORS,\n",
    "    )\n",
    "\n",
    "    docs_processed = []\n",
    "    for doc in tqdm(knowledge_base):\n",
    "        docs_processed += text_splitter.split_documents([doc])\n",
    "\n",
    "    # Remove duplicates\n",
    "    unique_texts = {}\n",
    "    docs_processed_unique = []\n",
    "    for doc in tqdm(docs_processed):\n",
    "        if doc.page_content not in unique_texts:\n",
    "            unique_texts[doc.page_content] = True\n",
    "            docs_processed_unique.append(doc)\n",
    "\n",
    "    return docs_processed_unique\n",
    "\n",
    "\n",
    "docs_processed = split_documents(\n",
    "    512, \n",
    "    RAW_KNOWLEDGE_BASE,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e776aef-3864-43f8-9ff3-327fb86074e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Knowledge Base\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    multi_process=True,\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # set True for cosine similarity\n",
    ")\n",
    "\n",
    "KNOWLEDGE_VECTOR_DATABASE = FAISS.from_documents(\n",
    "    docs_processed, embedding_model, distance_strategy=DistanceStrategy.COSINE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "071d7cef-7107-4a2d-ac54-1f69f6b5b827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting retrieval for user_query='นายวิษณุ เครืองาม พูดถึง นายสุรชัย เลี้ยงบุญเลิศชัย เรื่องอะไร'...\n",
      "\n",
      "==================================Top document==================================\n",
      "เผื่อมีน้องไม่ทันใช้? ไม่เป็นไร ใช้ลูกคนอื่นก็ได้ครับผม เห็นว่ามีส่วนร่วมในการเล่นเรื่องเจ้าบ้านเจ้าเรือนด้วย? ผมก็ได้ยินอยู่นะ แต่ว่ายังไม่ได้รับการคอนเฟิร์มกับทางช่อง ผมก็เพิ่งปิดเรื่องหัวใจปฐพี และนางสาวทองสร้อย เค้าได้มีการติดต่อมาทางช่องไหม? คือถ้าโดยหลักการแล้ว ผมเป็นนักแสดงช่อง 3 ก็ยังไม่ได้รับคำสั่งจากทางช่อง ผมก็ได้ยินนะครับแต่ผมยังไม่ได้รับคำสั่งจากทางช่อง ถ้าได้เล่นจริงๆ ก็จะเป็นพระรอง เพราะพี่ติ๊ก เจษฎาภรณ์เป็นพระเอก ผมไม่รู้สึกอะไร เพราะผมเป็นนักแสดง ผมเล่นได้ทุกบท ไม่เกี่ยงบทใช่ไหม? ผมก็ไม่เคยเลือกอยู่แล้วนะ ตั้งแต่เป็นนักแสดงมา ก็จะเป็นทางช่องเลือกให้หมดทุกอย่าง เราเป็นพระเอกมาตลอด แต่เรื่องนี้มีพระเอกอีกคนนึง? ผมก็เคยเล่นพระเอก 3 คนก็เคย 2 คนก็เคย มันไม่ใช่ปัญหาหรอกครับ ประเด็นมันไม่ได้อยู่ตรงนั้น อย่าไปทำให้มันมีประเด็นเลย\n",
      "==================================Metadata==================================\n",
      "{'source': 'https://www.thairath.co.th/content/478136', 'start_index': 1883}\n"
     ]
    }
   ],
   "source": [
    "# embed a user query in the same space\n",
    "user_query = \"นายวิษณุ เครืองาม พูดถึง นายสุรชัย เลี้ยงบุญเลิศชัย เรื่องอะไร\"\n",
    "# user_query = thai_tok(user_query)\n",
    "query_vector = embedding_model.embed_query(user_query)\n",
    "\n",
    "print(f\"\\nStarting retrieval for {user_query=}...\")\n",
    "retrieved_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=user_query, k=5)\n",
    "print(\n",
    "    \"\\n==================================Top document==================================\"\n",
    ")\n",
    "print(retrieved_docs[0].page_content)\n",
    "print(\"==================================Metadata==================================\")\n",
    "print(retrieved_docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf8f7db4-c06c-4000-9341-f167c1aca004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597a16e3bbdc420794c49e3c25e26822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/698 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c189750c5e164369851ad279135a2b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35ee50b1c1140f6bf267c2671c5d56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f14fb69416b44bca8e4d5df035db08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f256a6f7b94fee96f2be8ec5c0c357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00aafc16aa74b68822312777a6ae338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/2.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771670b06afd46518ec58a1c31e0fde5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f7e6f8955141a5a42bc7692a0f9367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5bf10d4c3f45038b002fa1a97899a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465ce6996dc843a18afb1c307c22d9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9388e69fa9744bbd825655bd856cce66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c7f966d9fc40bd8b4ec30d377dafcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/555 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add bos\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# Model and tokenizer loading\n",
    "READER_MODEL_NAME = \"SeaLLMs/SeaLLM-7B-v2.5\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    READER_MODEL_NAME, quantization_config=bnb_config\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(READER_MODEL_NAME)\n",
    "\n",
    "# Ensure '<bos>' token is added if not handled by the tokenizer\n",
    "def ensure_bos(token_ids):\n",
    "    bos_token_id = tokenizer.bos_token_id\n",
    "    if token_ids[0] != bos_token_id:\n",
    "        return [bos_token_id] + token_ids\n",
    "    return token_ids\n",
    "    \n",
    "# Define LLM model\n",
    "READER_LLM = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    # repetition_penalty=1.1,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=200,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8c27c60-5657-4751-9939-f7820715c848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><|im_start|>system\n",
      "Using the information contained in the context,\n",
      "give a comprehensive answer to the question.\n",
      "Respond only to the question asked, response should be concise and relevant to the question.\n",
      "Provide the number of the source document when relevant.\n",
      "If the answer cannot be deduced from the context, do not give an answer.<eos>\n",
      "<|im_start|>user\n",
      "Context:\n",
      "{context}\n",
      "---\n",
      "Now here is the question you need to answer.\n",
      "\n",
      "Question: {question}<eos>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define prompt\n",
    "prompt_in_chat_format = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"Using the information contained in the context,\n",
    "give a comprehensive answer to the question.\n",
    "Respond only to the question asked, response should be concise and relevant to the question.\n",
    "Provide the number of the source document when relevant.\n",
    "If the answer cannot be deduced from the context, do not give an answer.\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Context:\n",
    "{context}\n",
    "---\n",
    "Now here is the question you need to answer.\n",
    "\n",
    "Question: {question}\"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n",
    "    prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "print(RAG_PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fff9b7a-c468-46b4-b08a-a6501b3ca69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "นายวิษณุ เครืองาม พูดถึง นายสุรชัย เลี้ยงบุญเลิศชัย เรื่องการที่นายสุรชัย เลี้ยงบุญเลิศชัย มีการติดต่อกับทางช่อง 3 เพื่อขอรับคำสั่งในการเล่นเรื่องเจ้าบ้านเจ้าเรือน แต่ยังไม่ได้รับการคอนเฟิร์มกับทางช่อง และยังไม่ได้รับคำสั่งจากทางช่อง\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs_text = [\n",
    "    doc.page_content for doc in retrieved_docs\n",
    "]  # we only need the text of the documents\n",
    "context = \"\\nExtracted documents:\\n\"\n",
    "context += \"\".join(\n",
    "    [f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)]\n",
    ")\n",
    "\n",
    "final_prompt = RAG_PROMPT_TEMPLATE.format(\n",
    "    question=user_query, context=context\n",
    ")\n",
    "\n",
    "# Redact an answer\n",
    "answer = READER_LLM(final_prompt)[0][\"generated_text\"]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67587545-0906-459f-9376-0eae6b3fb474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><|im_start|>system\n",
      "Using the information contained in the context,\n",
      "give a comprehensive answer to the question.\n",
      "Respond only to the question asked, response should be concise and relevant to the question.\n",
      "Provide the number of the source document when relevant.\n",
      "If the answer cannot be deduced from the context, do not give an answer.<eos>\n",
      "<|im_start|>user\n",
      "Context:\n",
      "\n",
      "Extracted documents:\n",
      "Document 0:::\n",
      "เผื่อมีน้องไม่ทันใช้? ไม่เป็นไร ใช้ลูกคนอื่นก็ได้ครับผม เห็นว่ามีส่วนร่วมในการเล่นเรื่องเจ้าบ้านเจ้าเรือนด้วย? ผมก็ได้ยินอยู่นะ แต่ว่ายังไม่ได้รับการคอนเฟิร์มกับทางช่อง ผมก็เพิ่งปิดเรื่องหัวใจปฐพี และนางสาวทองสร้อย เค้าได้มีการติดต่อมาทางช่องไหม? คือถ้าโดยหลักการแล้ว ผมเป็นนักแสดงช่อง 3 ก็ยังไม่ได้รับคำสั่งจากทางช่อง ผมก็ได้ยินนะครับแต่ผมยังไม่ได้รับคำสั่งจากทางช่อง ถ้าได้เล่นจริงๆ ก็จะเป็นพระรอง เพราะพี่ติ๊ก เจษฎาภรณ์เป็นพระเอก ผมไม่รู้สึกอะไร เพราะผมเป็นนักแสดง ผมเล่นได้ทุกบท ไม่เกี่ยงบทใช่ไหม? ผมก็ไม่เคยเลือกอยู่แล้วนะ ตั้งแต่เป็นนักแสดงมา ก็จะเป็นทางช่องเลือกให้หมดทุกอย่าง เราเป็นพระเอกมาตลอด แต่เรื่องนี้มีพระเอกอีกคนนึง? ผมก็เคยเล่นพระเอก 3 คนก็เคย 2 คนก็เคย มันไม่ใช่ปัญหาหรอกครับ ประเด็นมันไม่ได้อยู่ตรงนั้น อย่าไปทำให้มันมีประเด็นเลยDocument 1:::\n",
      "ยอมใจ สารวัตรโจ้ พ.ต.ต.ธิติสรรค์ อุทธนพล จริงๆ เพราะหลังจากวันนี้มีเรื่องฮือฮากับบิลบอร์ดโฆษณาริมทางด่วนมีป้ายบิ๊กบึ้มบอก แฮปปี้เบิร์ธเดย์นางร้ายหน้าสวย เมย์ พิชญ์นาฏ สาขากร ที่เกิดวันนี้ (22 พ.ค.) งานนี้ฮือฮาหาตัวคนทำอยู่นานสุดท้ายก็เฉลยว่าเป็นผลงานของ สารวัตรโจ้ ที่ทำเพื่อ เมย์ เรื่องนี้ บันเทิงไทยรัฐออนไลน์ ต่อสายด่วนไปถามจากปาก สารวัตรโจ้,บิลบอร์ดของสารวัตรโจ้ใช่มั้ยคะ ใช่ครับแถวทางก่อนลงอนุสาวรีย์ชัยสมรภูมิ ป๋ามากจริงๆ อันนี้ ลงทุนไปเยอะมั้ยเอ่ย ไม่หรอกครับ ผมลงแค่จุดเดียว คิดอย่างไรถึงทำ ก็อยากทำอะไรดีๆ ให้เขา ก็ตามที่เขียนในอินสตาแกรมมันเป็นความรู้สึกของผมที่มาจากใจจริงๆ ,มีฟีดแบ็กจากเมย์มาหรือยังค่ะ อันนี้ผมขอเงียบไว้ดีกว่าครับDocument 2:::\n",
      "ก็กลับมาหลอกหลอนเราได้อีก,ไม่รู้เป็นครั้งที่เท่าไหร่แล้ว พับผ่าซิ,พาวเวอร์บอมบ์Document 3:::\n",
      "รอดสวาสดิ์ ผกก.ตม.จว.สระแก้ว ได้สั่งการให้ จนท.ตม.ประจำ ด่าน ตม.อรัญประเทศฯ ประชาสัมพันธ์และแจ้งเตือนคนไทยที่ทำงานอยู่ในฝั่งปอยเปต ประเทศกัมพูชา ให้ระมัดระวังพกหนังสือเดินทางตลอดเวลา และห้ามทำผิดกฎหมายในกัมพูชา โดยเฉพาะช่วงเวลากลางคืนห้ามออกมาเดินเล่นในตลาดปอยเปตฯ และอย่าพยายามปิดบังใบหน้า หรือใส่หมวกคลุมใบหน้าเพราะจะทำให้ถูก จนท.กัมพูชา ตรวจค้นหรือเกิดสงสัยได้,จากการตรวจสอบความเคลื่อนไหวในกรุงปอยเปต ประเทศกัมพูชา พบว่าทางรัฐบาลกัมพูชา ได้มอบหมายให้ พล.อ.เค็ง ซาเมด รอง ผบ.ตร.กัมพูชา ซึ่งรับผิดชอบดูแลพื้นที่ตามแนวชายแดนประเทศกัมพูชาทั่วประเทศ รับผิดชอบและสั่งการให้ จนท.ทหารและตำรวจกัมพูชาปฏิบัติการเข้มป้องกันและสกัดกั้นไม่ให้กลุ่มกบฏกัมพูชาสามารถลักลอบเดินทางเข้าประเทศกัมพูชา ได้ ,เบื้องต้นมีการสั่งการให้ พล.ท.เป็ก วันนาDocument 4:::\n",
      "บาร์ดสลีย์, วีแลน, เอ็นซอนซี, อาร์เนาโตวิช, อดัม, วอลเตอร์ส และ ดิยุฟ น่าจะมีลุ้นลงตัวจริง,************************************,ควีนส์ปาร์ค เรนเจอร์ส-นิวคาสเซิล ยูไนเต็ด (21.00 น.),สนาม :, ลอฟตัส โรด สเตเดี้ยม,ผู้ตัดสิน :, ลี โปรเบิร์ต,ขุนพลทหารเสือราชินี ควีนส์ปาร์ค เรนเจอร์ส ทีมบ๊วย มี 27 แต้ม จาก 36 นัด ไม่ชนะใครมา 5 นัดติดต่อกันแล้ว ทำให้ตกชั้นไปเรียบร้อย นัดนี้ลงเล่นในถิ่นตัวเอง กุนซือ คริส แรมซีย์ สั่งลูกทีมเล่นเต็มที่เพื่อแฟนบอล,สภาพทีมล่าสุด ซานโดร กับ เฟอร์ดินานด์ มีปัญหาส่วนตัว ลงช่วยทีมไม่ได้ ส่วน ดัฟตี้, ทารับท์, ตราโอเร และ ฟาเออร์ลิน ลงไม่ได้เพราะเจ็บ ขณะที่ อิสลา ยังรอทดสอบความฟิต คาดว่าตัวหลักอย่าง กรีน, คอลเกอร์, ดันน์, โอนัวฮา, ฮิลล์, บาร์ตัน, ฟิลลิปส์, เฮนรี, เฟอร์, ซาโมรา และ ออสติน\n",
      "---\n",
      "Now here is the question you need to answer.\n",
      "\n",
      "Question: นายวิษณุ เครืองาม พูดถึง นายสุรชัย เลี้ยงบุญเลิศชัย เรื่องอะไร<eos>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(context)\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2564dd2e-bfe4-4a66-a8a1-86d7cf52c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerank answers\n",
    "from ragatouille import RAGPretrainedModel\n",
    "\n",
    "RERANKER = RAGPretrainedModel.from_pretrained(\"antoinelouis/colbert-xm\") # multilingual\n",
    "\n",
    "def answer_with_rag(\n",
    "    question: str,\n",
    "    llm: Pipeline,\n",
    "    knowledge_index: FAISS,\n",
    "    reranker: Optional[RAGPretrainedModel] = None,\n",
    "    num_retrieved_docs: int = 30,\n",
    "    num_docs_final: int = 5,\n",
    ") -> Tuple[str, List[LangchainDocument]]:\n",
    "    # Gather documents with retriever\n",
    "    print(\"=> Retrieving documents...\")\n",
    "    relevant_docs = knowledge_index.similarity_search(\n",
    "        query=question, k=num_retrieved_docs\n",
    "    )\n",
    "    relevant_docs = [doc.page_content for doc in relevant_docs]  # keep only the text\n",
    "\n",
    "    # Optionally rerank results\n",
    "    if reranker:\n",
    "        print(\"=> Reranking documents...\")\n",
    "        relevant_docs = reranker.rerank(question, relevant_docs, k=num_docs_final)\n",
    "        relevant_docs = [doc[\"content\"] for doc in relevant_docs]\n",
    "\n",
    "    relevant_docs = relevant_docs[:num_docs_final]\n",
    "\n",
    "    # Build the final prompt\n",
    "    context = \"\\nExtracted documents:\\n\"\n",
    "    context += \"\".join(\n",
    "        [f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(relevant_docs)]\n",
    "    )\n",
    "\n",
    "    final_prompt = RAG_PROMPT_TEMPLATE.format(question=question, context=context)\n",
    "\n",
    "    # Redact an answer\n",
    "    print(\"=> Generating answer...\")\n",
    "    answer = llm(final_prompt)[0][\"generated_text\"]\n",
    "\n",
    "    return answer, relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f57885d-e034-43ee-ba01-4863ef4a31fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.11/lib/python3.11/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================Answer==================================\n",
      "นายวิษณุ เครืองามไม่ได้พูดถึงนายสุรชัย เลี้ยงบุญเลิศชัยในบริบทที่ให้มา\n",
      "==================================Source docs==================================\n",
      "Document 0------------------------------------------------------------\n",
      "สนช.บางส่วนที่ยังติดใจขอสงวนคำแปรญัตติไว้อภิปรายในที่ประชุม สนช. เนื่องจากอยากให้ กกต.ชุดปัจจุบันทำหน้าที่ต่อไปจนครบวาระ,นายสมชัย ศรีสุทธิยากร กกต.ด้านบริหารกลาง กล่าวว่า หากให้ภาพอนาคตเลวร้ายสุดคือให้ กกต.ขาดคุณสมบัติตามรัฐธรรมนูญใหม่ คนแรกที่ขาดคุณสมบัติคือนายประวิช รัตนเพียร กกต.ด้านการมีส่วนร่วม ส่วนตนต้องยื่นหลักฐานทำงานภาคประชาสังคมหากกรรมการสรรหาไม่รับฟังจะพ้นจากตำแหน่ง อีก 2 คนจะหมดวาระเพราะอายุครบ 70 ปี คือนายบุญส่ง น้อยโสภณ เดือน ก.ค.61 นายศุภชัย เดือน ก.พ.62 เหลือนายธีรวัฒน์ ธีรโรจน์วิทย์ กกต.ด้านพรรคการเมืองคนเดียว ถ้านายธีรวัฒน์ ถูกตรวจสอบด้านจริยธรรม อาจทำให้การเลือกตั้งหลังเดือน ก.พ.62 อยู่ในมือ กกต.ใหม่ทั้ง 7 คน ส่วนภาพดีสุดคือ สนช.ยึดคุณสมบัติตามรัฐธรรมนูญเดิมให้\n",
      "Document 1------------------------------------------------------------\n",
      "ส่วนถ้ามีคนลาออกแล้วจะตั้งใครมาดำรงตำแหน่งแทน เรื่องนี้ คสช.คงจะเป็นผู้ตัดสินใจ,เมื่อถามถึงเหตุผลที่ กรธ. จะเอาข้อบังคับ ส.ส. และ ส.ว. มาบังคับใช้กับ สนช. นั้น นายมีชัย กล่าวว่า ที่ต้องทำแบบนี้เพื่อจะได้ไม่เป็นการดูว่าจะเลือกที่รักมักที่ชัง เพราะถ้าข้อบังคับนั้นใช้กับ ส.ส. และ ส.ว. ได้ ก็ต้องบังคับใช้กับ สนช. ได้เช่นกัน ซึ่งก็คงจะมีข้อยกเว้นกับ สนช. ที่เป็นข้าราชการมาก่อน แต่ถ้าสมาชิก สนช. คนไหนรู้ตัวว่าตัวเองขาดคุณสมบัติตามรัฐธรรมนูญใหม่นั้น ตนเชื่อว่าเขาคงจะรู้ตัวและลาออกไปเอง,นายมีชัย กล่าวต่อว่า ช่วงร่างรัฐธรรมนูญฉบับนี้นั้น ได้มีรายละเอียดที่เป็นของใหม่เยอะ ดังนั้นต้องฟังความเห็นอย่างกว้างขวางด้วย โดยเฉพาะในส่วนขององค์กรอิสระต่างๆ ในช่วงหลังจากวันที่ 29 ม.ค. ที่ร่างรัฐธรรมนูญร่างแรกออกมาให้สังคมได้เห็น.\n",
      "Document 2------------------------------------------------------------\n",
      "เมื่อเวลา 07.45 น. วันที่ 28 ก.ค. 58 พ.ต.อ.ปพนวัฒน์ ขัตติยะวรานันท์ ผกก.สภ.ยะหา จ.ยะลา พ.ต.ท.ประสม หลวงพูล รอง ผกก.สส. พร้อมด้วย นายชัยชนะ กฤตยานาถ นายอำเภอยะหา สนธิกำลังเจ้าหน้าที่หลายฝ่าย รุดตรวจสอบเหตุยิงกันตายที่บ้านกูวิง หมู่ 6 ต.บาโระ,ที่เกิดเหตุอยู่ใกล้บ้านเลขที่ 105 หมู่ 6 มีเลือดกองใหญ่เปรอะบนพื้น พบปลอกกระสุนปืนขนาด 9 มม. เก็บรวบรวมไว้ได้ 11 ปลอก ส่วนผู้ถูกยิงทราบชื่อนายมะหะมะเปาซี อุเซ็ง อายุ 40 ปี อยู่บ้านเลขที่ 12 หมู่ 2 บ้านตันหยง ต.บาโร๊ะ ถูกกระสุนรวม 4 นัด เจาะตามร่างกายและแขนซ้ายกับขาขวา นอนตายจมกองเลือดอยู่บนพื้น ห่างจากจุดเกิดเหตุไปราว 50 เมตร ภายในสวนยางพารา พบเพิงชั่วคราว หลังคามุงใบไม้ ใกล้ๆ กัน พบเศษใบพืชกระท่อมต้ม ตาชั่งใหญ่และเล็กรวม 2 ตัว กับอุปกรณ์การต้มน้ำใบกระท่อมผลิตยาสูตร 4x100\n",
      "Document 3------------------------------------------------------------\n",
      "ในช่วงเวลาที่ต้องการใช้เงินในการดำรงชีวิตอย่างเร่งด่วนในสถานการณ์ที่ต้องหยุดงานไม่มีรายได้เลขาธิการแก้ปัญหาทันทีเกี่ยวกับเรื่องนี้ นายทศพล กฤตวงศ์วิมาน เลขาธิการสำนักงานประกันสังคม เปิดเผยว่า ได้เข้าชี้แจงประเด็นปัญหาที่เกิดขึ้นต่อ ม.ร.ว.จัตุมงคล โสณกุล รมว.แรงงาน หลังจากนั้นได้ออกคำสั่งการด่วนกระทรวงแรงงานที่ 219/2563 แต่งตั้งพนักงานเจ้าหน้าที่ตาม พ.ร.บ.ประกันสังคม พ.ศ. 2563 ให้แต่งตั้งข้าราชการกรมสวัสดิการและคุ้มครองแรงงาน ทั้งในส่วนกลาง ส่วนภูมิภาค และเขตพื้นที่กรุงเทพฯ กว่า 1200 ราย เป็นพนักงานเจ้าหน้าที่ตรวจสอบข้อมูล กรณีนายจ้างหยุดกิจการทั้งหมดหรือบางส่วนเป็นการชั่วคราว พร้อมรับรองผลการตรวจสอบ และรายงานต่อสำนักงานประกันสังคม เพื่ออำนวยความสะดวกแก่นายจ้าง และผู้ประกันตน เพื่อให้สามารถจ่ายเงินให้แก่ผู้ขอรับสิทธิประโยชน์ได้รวดเร็วมากขึ้นมท.2 เผย กปน.อัดฉีด 4+1ขณะที่ นายนิพนธ์ บุญญามณี รมช.มหาดไทย เปิดเผยว่า\n",
      "Document 4------------------------------------------------------------\n",
      "นายประภาส ขุนพิทักษ์ นายอำเภอท้ายเหมือง ในฐานะตัวแทนชาว จ.พังงา มูลนิธิเต่าทะเลหาดไม้ขาว และกองทุนอนุรักษ์เต่าทะเลถิ่นอาศัย มอบเงินจำนวน 20000 บาท ให้กับนายมณี นาหาญ และนางอุไร นาหาญ สองสามีภรรยา ซึ่งเป็นผู้พบหลุมไข่เต่ามะเฟือง บริเวณชายหาดบ้านท่าแตง หมู่ 6 ต.นาเตย อ.ท้ายเหมือง จ.พังงา และแจ้งให้เจ้าหน้าที่กรมประมง และอุทยานลำปี-ท้ายเหมือง เข้าตรวจสอบ ทั้งนี้เพื่อเป็นขวัญกำลังใจในการร่วมกันอนุรักษ์ทรัพยากรธรรมชาตินายมณี เล่าว่า ขณะออกหาปลาบริเวณชายหาด ได้วางอุปกรณ์หาปลาไว้ใกล้กับหลุมที่เต่าขึ้นมาวางไข่ เมื่อสังเกตเห็นว่าเป็นหลุมเต่าสำหรับวางไข่ จึงสำรวจบริเวณรอบๆ หลุม จนแน่ใจว่าไม่มีร่องรอยของคนบริเวณนี้ จึงทำสัญลักษณ์ขีดเป็นวงกลมรอบรังไข่เต่าและบอกกับภรรยาว่าอย่าเข้าไปใกล้\n"
     ]
    }
   ],
   "source": [
    "# Final\n",
    "question = \"นายวิษณุ เครืองาม พูดถึง นายสุรชัย เลี้ยงบุญเลิศชัย เรื่องอะไร\"\n",
    "\n",
    "answer, relevant_docs = answer_with_rag(\n",
    "    question, READER_LLM, KNOWLEDGE_VECTOR_DATABASE, reranker=RERANKER\n",
    ")\n",
    "\n",
    "print(\"==================================Answer==================================\")\n",
    "print(f\"{answer}\")\n",
    "print(\"==================================Source docs==================================\")\n",
    "for i, doc in enumerate(relevant_docs):\n",
    "    print(f\"Document {i}------------------------------------------------------------\")\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e33b1-2b40-4a4d-a365-a34851e7d373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
